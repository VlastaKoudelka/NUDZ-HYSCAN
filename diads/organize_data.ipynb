{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b42838b-47be-4e5b-a947-bd2b2931dadb",
   "metadata": {},
   "source": [
    "### Define directories and data across conditions\n",
    "- make sure your data exported from the BVA are in the input directiory according to inputPath variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c416e3c-f71b-4e67-b175-0bdf885945b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "inputPath = '/home/koudelka/Projects/LSD_FilipTrybusek/input/'\n",
    "outputPath = '/home/koudelka/Projects/LSD_FilipTrybusek/output/'\n",
    "pipePath = '/home/koudelka/Projects/LSD_FilipTrybusek/pipe/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f4c87-a06d-42bf-bb09-866b414fd085",
   "metadata": {},
   "source": [
    "### Define a list of data to be processed\n",
    "\n",
    "- the first dimmension is across conditions\n",
    "- the second dimmension is across diads (groups)\n",
    "- the third dimmension is across individual subjects within groups\n",
    " - in the following exapmple I have one group (one sample), two conditions (EO and EC) and two subjects (S1 and S2)\n",
    "- define condition names, e.g. ['EO','EC']\n",
    " - the order in condLab has to correspond to the order in dataNames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a81100-1f34-41e3-9faa-0bb2547c6be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataNames = [[['S1_C1_A1_Resting_Segmentation RS EO.vhdr', 'S2_C1_A1_Resting_Segmentation RS EO.vhdr']],\n",
    "             [['S1_C1_A1_Resting_Segmentation RS EC.vhdr','S2_C1_A1_Resting_Segmentation RS EC.vhdr']]]\n",
    "dataNames = np.array(dataNames)\n",
    "condLab = ['EO','EC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f9edc-acd1-4531-93aa-1367ae9bc641",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "- plot files across all conditions from the first group and the first subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f445d9-2112-423d-ac0a-072016bf499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1_C1_A1_Resting_Segmentation RS EO.vhdr'\n",
      " 'S1_C1_A1_Resting_Segmentation RS EC.vhdr']\n"
     ]
    }
   ],
   "source": [
    "print(dataNames[:,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6bb85b-18e2-4c26-aaae-bb593e3f2bbd",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "- plot all subjects in the first condition from the first group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a54fa73-06ac-4c5e-96e3-cb89aa4eb268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1_C1_A1_Resting_Segmentation RS EO.vhdr'\n",
      " 'S2_C1_A1_Resting_Segmentation RS EO.vhdr']\n"
     ]
    }
   ],
   "source": [
    "print(dataNames[0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8c380-5828-4df6-8647-72e3948a2138",
   "metadata": {},
   "source": [
    "### Init the script and load the data\n",
    "- specify a band of interest\n",
    "- specify channels to be dropped\n",
    "- load the specified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdf5743-14cc-4244-9c6f-403e542b7241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... S1_C1_A1_Resting_Segmentation RS EO.vhdr\n",
      "Loading... S2_C1_A1_Resting_Segmentation RS EO.vhdr\n",
      "Loading... S1_C1_A1_Resting_Segmentation RS EC.vhdr\n",
      "Loading... S2_C1_A1_Resting_Segmentation RS EC.vhdr\n"
     ]
    }
   ],
   "source": [
    "# bandFreqs = [[1,4],[1,8],[8,12],[12,35],[35,45]]\n",
    "# bandLabls = ['Delta','Theta','Alpha','Beta','Gamma']\n",
    "bandFreqs = [8,12]\n",
    "bandLabels = ['Alpha']\n",
    "nBands = len(bandFreqs) \n",
    "dropChan = ['M1','M2','EOG','ECG','RESP','RESP2']\n",
    "\n",
    "def init_list(dims, val):\n",
    "    if len(dims) == 0:\n",
    "        raise ValueError(\"Requires at least 1 dimension.\")\n",
    "    if len(dims) == 1:\n",
    "        return [val for _ in range(dims[0])]\n",
    "    return [init_list(dims[1:], val=val) for _ in range(dims[0])]\n",
    "\n",
    "nC,nG,nS = dataNames.shape\n",
    "dataRaw = init_list(dataNames.shape, val=0)\n",
    "for cIdx, condIns in enumerate(dataNames):\n",
    "    for gIdx, groupIns in enumerate(condIns):\n",
    "        for sIdx, subIns in enumerate(groupIns):\n",
    "            print('Loading... ' + subIns)\n",
    "            dataRaw[cIdx][gIdx][sIdx] = mne.io.read_raw_brainvision(inputPath + subIns, verbose='error',preload=True).drop_channels(dropChan,on_missing='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139a93c-c417-4b90-9ec8-4018c0b846b8",
   "metadata": {},
   "source": [
    "### Rename channels according to subjects ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c184a5-9e75-46da-8848-b3f8b4c69876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename channel labels according to subject IDs\n",
    "for cIdx, condIns in enumerate(dataRaw):\n",
    "    for gIdx, groupIns in enumerate(condIns):\n",
    "        for sIdx, subIns in enumerate(groupIns):\n",
    "            for chIdx, chanIns in enumerate(subIns.ch_names):\n",
    "                dataRaw[cIdx][gIdx][sIdx].ch_names[chIdx] = chanIns + '_sub' + str(sIdx+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a27b48-a8f3-4ebb-8d59-437fb5c195a7",
   "metadata": {},
   "source": [
    "### Prepare data for merging group wise\n",
    "- concatanate across subjects in np array\n",
    "- generate a new list of channel names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32fc1775-9ecd-4cf0-bd34-0f94a467e748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fs = dataRaw[0][0][0].info['sfreq']\n",
    "nCh = dataRaw[0][0][0].info['nchan']\n",
    "newNchan = nCh*nS\n",
    "\n",
    "#create join np data array and join channel labels out of rawData object\n",
    "newChanNames = []\n",
    "npData = init_list((nC,nG),val=0)\n",
    "for cIdx, condIns in enumerate(dataRaw):\n",
    "    for gIdx, groupIns in enumerate(condIns):\n",
    "        for sIdx, subIns in enumerate(groupIns):\n",
    "            if sIdx == 0:\n",
    "                npData[cIdx][gIdx] = subIns._data\n",
    "            else:\n",
    "                npData[cIdx][gIdx] = np.append(npData[cIdx][gIdx], subIns._data, axis = 0)\n",
    "            if (cIdx == 0) and (gIdx == 0):\n",
    "                newChanNames = newChanNames + subIns.ch_names\n",
    "     \n",
    "newChanTypes = [\"eeg\"]*newNchan\n",
    "newInfo = mne.create_info(newChanNames, ch_types=newChanTypes, sfreq=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd732ae-8d30-4e8e-91fb-8e802777d6c9",
   "metadata": {},
   "source": [
    "### Create mne raw object out of np array and concatenate across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec452b7-4ab0-4e02-8315-c2ad6d33ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=120001\n",
      "    Range : 0 ... 120000 =      0.000 ...   240.000 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=119996\n",
      "    Range : 0 ... 119995 =      0.000 ...   239.990 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "mneData = init_list((nC,nG),val=0)\n",
    "for cIdx, condIns in enumerate(npData):\n",
    "    for gIdx, groupIns in enumerate(condIns):\n",
    "        mneData[cIdx][gIdx] = mne.io.RawArray(groupIns, newInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72374053-0957-4666-ba71-f0564edb6c1b",
   "metadata": {},
   "source": [
    "### Merge bad epochs from single subject annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c80dcc6-3b51-46c3-97e8-f676e98df75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cIdx, condIns in enumerate(dataRaw):\n",
    "    for gIdx, groupIns in enumerate(condIns):        \n",
    "        annotItem = []\n",
    "        for sIdx, subIns in enumerate(groupIns):\n",
    "            for annotIdx, annotIns in enumerate(subIns.annotations.description):\n",
    "                if 'Bad Interval' in annotIns:\n",
    "                    annotItem.append([subIns.annotations.onset[annotIdx], subIns.annotations.duration[annotIdx]])     \n",
    "        #item list to np array\n",
    "        annotItem = np.array(annotItem) \n",
    "        nAnnot = annotItem.shape[0]\n",
    "\n",
    "        #add the annotations to the data\n",
    "        mneData[cIdx][gIdx].annotations.append(annotItem[:,0],annotItem[:,1],['bad']*nAnnot)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6395e11-aa6b-44bf-8136-85f2f82eb75b",
   "metadata": {},
   "source": [
    "### Resample data before further computations\n",
    "- set new sampling frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faaa04bd-0a37-4848-8959-f802de2e3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "newFs = 128\n",
    "for cIdx, condIns in enumerate(mneData):\n",
    "    for gIdx, groupIns in enumerate(condIns):\n",
    "        mneData[cIdx][gIdx] = groupIns.resample(newFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139f94a-e6bd-4c44-a39a-7bb1620352c5",
   "metadata": {},
   "source": [
    "### Filter data to bands, make epochs, exclude bad epochs\n",
    "- choose the epoch length\n",
    "- choose overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "511659b6-4505-4f54-8de7-8b99f45cd45d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 12 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 12.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz)\n",
      "- Filter length: 213 samples (1.664 s)\n",
      "\n",
      "Not setting metadata\n",
      "479 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 479 events and 128 original time points ...\n",
      "232 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 12 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 12.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz)\n",
      "- Filter length: 213 samples (1.664 s)\n",
      "\n",
      "Not setting metadata\n",
      "478 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 478 events and 128 original time points ...\n",
      "9 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "windowLength = 1 # in seconds\n",
    "windowOverlap = 0.5\n",
    "corrList = []\n",
    "\n",
    "epochData = init_list((nC,nG),val=0)\n",
    "for cIdx, condIns in enumerate(mneData):\n",
    "    for gIdx, groupIns in enumerate(condIns):\n",
    "        mneData[cIdx][gIdx].filter(bandFreqs[0],bandFreqs[1], fir_design='firwin') #alfa\n",
    "        epochs = mne.make_fixed_length_epochs(mneData[cIdx][gIdx], duration = windowLength, preload=True, reject_by_annotation=True,overlap = windowOverlap)\n",
    "        epochData = epochs.get_data(copy=True)\n",
    "        np.savez(pipePath + 'c' + str(cIdx) + 'g' + str(gIdx), epochData=epochData, condLab=condLab)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
